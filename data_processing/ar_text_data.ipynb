{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview (first 1000 chars):\n",
      "الإسلامدينسماويتوحيدي،يؤمنأتباعهبأنلاإلهإلاالله،[8]وأنمحمدًارسولالله.[9][10]ويعرفونباسمالمسلمين.[11]يُعلّمالإسلامأناللههورحيم،ولديهالقدرةالكلية،وهوواحد،[12]وقدأرشدالبشريةمنخلالالأنبياءوالرسل،والكتبالمقدسةوالآيات.[13]النصوصالأساسيةفيالإسلامهيالقرآن-الذيأوحيبهاللهإلىمحمدخلال23عامًافيمكةوالمدينة،[14][15]وينظرإليهالمسلمونعلىأنهكلمةاللهالحرفيةوالمعصومةعنالخطأ-والتعاليموالأمثلةالمعيارية(السنة)،والتيتشملالأحاديثالنبويةالخاصةبمحمد.يعتقدالمسلمونأنالإسلامهوالنسخةالكاملةالشاملةللعقيدةالتوحيديةالتيأُوحيَبهامراتعديدةإلىالأنبياء،كآدموإبراهيمونوحوداودويعقوبويوسفوصالحوهودويونسوموسىوزكرياويحييوعيسى.[16][17][18]يعتبرالمسلمونالقرآنالكريمالوحيالمطلقوالنهائيمنالله.[19]مثلالأديانالإبراهيميةالأخرى،فيالإسلامأيضاًحكمنهائييُمنحفيهالصالحونالجنةوغيرالصالحينالجحيم(جهنم).[20][21]تشملالمفاهيموالممارساتالدينيةأركانالإسلامالخمسة،وهيعباداتإجبارية،واتباعالشريعةالإسلامية،التيتمسكلجوانبالحياةوالمجتمعتقريبًا،منالأعمالالمصرفيةإلىالمرأةوالأخلاقوالبيئة.[22][23]مكةوالمدينةالمنورةوالقدسهيموطنلأقدسثلاثةمواقعفيالإسلام.[24]بغضالنظ...\n",
      "Full article stats:\n",
      "- Words: ~1 (Arabic token estimate)\n",
      "- Characters: 96,489\n",
      "Saved full text to 'islam_arabic_wikipedia.txt'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved full text to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mislam_arabic_wikipedia.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# For very long texts, you can chunk it for training\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     paragraphs \u001b[38;5;241m=\u001b[39m \u001b[43marticle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of paragraphs/sections: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(paragraphs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: empty separator"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# URL for the Arabic Wikipedia article on Islam\n",
    "url = 'https://ar.wikipedia.org/wiki/الإسلام'\n",
    "\n",
    "# Headers to mimic a browser (helps avoid blocks)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "def fetch_wikipedia_article(url, headers):\n",
    "    \"\"\"\n",
    "    Fetch the Wikipedia article and extract clean text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send GET request\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise error for bad status codes\n",
    "        \n",
    "        # Parse HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        \n",
    "        # Find the main content div (Wikipedia's structure)\n",
    "        content = soup.find('div', id='mw-content-text')\n",
    "        if not content:\n",
    "            raise ValueError(\"Could not find main content div\")\n",
    "        \n",
    "        # Remove unwanted elements: infobox, references, navigation, etc.\n",
    "        for element in content.find_all(['table', 'ul', 'ol', 'sup', 'div'], class_=re.compile(r'infobox|references|navbox|thumb|metadata')):\n",
    "            element.decompose()\n",
    "        \n",
    "        # Extract text from paragraphs and headings\n",
    "        text_elements = content.find_all(['p', 'h2', 'h3', 'h4'])\n",
    "        full_text = []\n",
    "        for elem in text_elements:\n",
    "            # Get text, clean whitespace, and skip short/empty elements\n",
    "            elem_text = elem.get_text(strip=True)\n",
    "            if len(elem_text) > 50:  # Filter out very short snippets\n",
    "                full_text.append(elem_text)\n",
    "        \n",
    "        # Join into full article text\n",
    "        article_text = ''.join(full_text)\n",
    "        \n",
    "        # Basic cleaning: remove extra newlines and Arabic-specific artifacts if needed\n",
    "        article_text = re.sub(r'\\s*', '', article_text)\n",
    "        \n",
    "        return article_text\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching page: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch the article\n",
    "article = fetch_wikipedia_article(url, headers)\n",
    "\n",
    "if article:\n",
    "    # Print a preview (first 1000 characters)\n",
    "    print(\"Preview (first 1000 chars):\")\n",
    "    print(article[:1000] + \"...\" if len(article) > 1000 else article)\n",
    "    \n",
    "    # Print stats\n",
    "    word_count = len(article.split())\n",
    "    char_count = len(article)\n",
    "    print(f\"Full article stats:\")\n",
    "    print(f\"- Words: ~{word_count:,} (Arabic token estimate)\")\n",
    "    print(f\"- Characters: {char_count:,}\")\n",
    "    \n",
    "    # Save to file for LLM use\n",
    "    with open('islam_arabic_wikipedia.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(article)\n",
    "    print(\"Saved full text to 'islam_arabic_wikipedia.txt'\")\n",
    "    \n",
    "    # For very long texts, you can chunk it for training\n",
    "    paragraphs = article.split('')\n",
    "    print(f\"Number of paragraphs/sections: {len(paragraphs)}\")\n",
    "else:\n",
    "    print(\"Failed to fetch article.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
